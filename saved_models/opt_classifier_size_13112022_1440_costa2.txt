Command line: main.py -ds 6 -ts 4 -e 22 -m nn_models.Model_3 -lt clasification -lf cross_entropy -of tmp/last_model_cl.pyt

Loading dataset with id 6
Loading dataset with id 4
Creating model: nn_models.Model_3
Cross entropy weights: tensor([0.2036, 0.7964])

Model: Model_3(
  (emb): Embedding(141, 64, padding_idx=0)
  (rnn): LSTM(64, 128)
  (lin): Linear(in_features=128, out_features=2, bias=True)
  (lin1): Linear(in_features=128, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=128, bias=True)
)

Loss function: CrossEntropyLoss()

Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)


** The training set (80.00% for training and 20.00% for validation)

Dataset: SequenceBasedBasicBlocksDataset(337256):
====================
Number of sequences: 337256
Input sizes: 141
Class distribution:
===================
Number of classes: 2

{0: '268607 (79.64)% ', 1: '68649 (20.36)% '}


** The test set

Dataset: SequenceBasedBasicBlocksDataset(169150):
====================
Number of sequences: 169150
Input sizes: 141
Class distribution:
===================
Number of classes: 2

{0: '134668 (79.61)% ', 1: '34482 (20.39)% '}


Epoch 001* 	 
	Train: LOSS F. (mean)=0.0195 (total=82.02,max=0.43,mean=0.02)	CLASS_OK=0.0060 (268187/269804 (%99.40))	TimeGain_OptLoss=0.0060 (197081.27/503264.08,563.00/92684.00)@(268187:213708:54479,348(4.76%),1269)	
	Val: LOSS F. (mean)=0.0213 (total=22.42,max=0.38,mean=0.02)	CLASS_OK=0.0065 (67011/67452 (%99.35))	TimeGain_OptLoss=0.0065 (49385.03/125641.66,220.00/23215.00)@(67011:53320:13691,131(7.71%),310)	
	Test: LOSS F. (mean)=0.0210 (total=55.47,max=0.43,mean=0.02)	CLASS_OK=0.0060 (168138/169150 (%99.40))	TimeGain_OptLoss=0.0060 (122547.88/310762.57,487.00/58171.00)@(168138:133913:34225,257(4.98%),755)	
Epoch 002 	 
	Train: LOSS F. (mean)=0.0246 (total=103.76,max=0.44,mean=0.02)	CLASS_OK=0.0115 (266688/269804 (%98.85))	TimeGain_OptLoss=0.0115 (160986.57/503264.08,145.00/92684.00)@(266688:211929:54759,68(0.22%),3048)	
	Val: LOSS F. (mean)=0.0263 (total=27.73,max=0.44,mean=0.03)	CLASS_OK=0.0116 (66669/67452 (%98.84))	TimeGain_OptLoss=0.0116 (39265.37/125641.66,43.00/23215.00)@(66669:52870:13799,23(0.48%),760)	
	Test: LOSS F. (mean)=0.0246 (total=65.09,max=0.70,mean=0.02)	CLASS_OK=0.0107 (167333/169150 (%98.93))	TimeGain_OptLoss=0.0107 (100428.63/310762.57,114.00/58171.00)@(167333:132912:34421,61(0.31%),1756)	
Epoch 003* 	 
	Train: LOSS F. (mean)=0.0139 (total=58.61,max=0.49,mean=0.01)	CLASS_OK=0.0060 (268187/269804 (%99.40))	TimeGain_OptLoss=0.0060 (172361.53/503264.08,176.00/92684.00)@(268187:213467:54720,107(0.87%),1510)	
	Val: LOSS F. (mean)=0.0154 (total=16.20,max=0.39,mean=0.02)	CLASS_OK=0.0062 (67034/67452 (%99.38))	TimeGain_OptLoss=0.0062 (41842.93/125641.66,70.00/23215.00)@(67034:53253:13781,41(1.00%),377)	
	Test: LOSS F. (mean)=0.0178 (total=46.98,max=0.66,mean=0.02)	CLASS_OK=0.0059 (168155/169150 (%99.41))	TimeGain_OptLoss=0.0059 (109343.37/310762.57,217.00/58171.00)@(168155:133786:34369,113(1.13%),882)	
Epoch 004* 	 
	Train: LOSS F. (mean)=0.0100 (total=42.23,max=0.27,mean=0.01)	CLASS_OK=0.0045 (268586/269804 (%99.55))	TimeGain_OptLoss=0.0045 (179661.50/503264.08,142.00/92684.00)@(268586:213850:54736,91(0.59%),1127)	
	Val: LOSS F. (mean)=0.0132 (total=13.87,max=0.28,mean=0.01)	CLASS_OK=0.0048 (67126/67452 (%99.52))	TimeGain_OptLoss=0.0048 (43877.27/125641.66,69.00/23215.00)@(67126:53346:13780,42(1.25%),284)	
	Test: LOSS F. (mean)=0.0161 (total=42.45,max=0.70,mean=0.02)	CLASS_OK=0.0050 (168312/169150 (%99.50))	TimeGain_OptLoss=0.0050 (113062.63/310762.57,260.00/58171.00)@(168312:133966:34346,136(1.35%),702)	
Epoch 005 	 
	Train: LOSS F. (mean)=0.0103 (total=43.60,max=0.19,mean=0.01)	CLASS_OK=0.0050 (268458/269804 (%99.50))	TimeGain_OptLoss=0.0050 (184258.56/503264.08,121.00/92684.00)@(268458:213711:54747,80(0.72%),1266)	
	Val: LOSS F. (mean)=0.0129 (total=13.64,max=0.21,mean=0.01)	CLASS_OK=0.0051 (67109/67452 (%99.49))	TimeGain_OptLoss=0.0051 (45417.69/125641.66,63.00/23215.00)@(67109:53326:13783,39(1.26%),304)	
	Test: LOSS F. (mean)=0.0158 (total=41.65,max=0.81,mean=0.02)	CLASS_OK=0.0054 (168243/169150 (%99.46))	TimeGain_OptLoss=0.0054 (114585.25/310762.57,174.00/58171.00)@(168243:133871:34372,110(1.10%),797)	
Epoch 006* 	 
	Train: LOSS F. (mean)=0.0076 (total=31.94,max=0.41,mean=0.01)	CLASS_OK=0.0036 (268829/269804 (%99.64))	TimeGain_OptLoss=0.0036 (187814.91/503264.08,157.00/92684.00)@(268829:214092:54737,90(1.06%),885)	
	Val: LOSS F. (mean)=0.0123 (total=12.97,max=0.50,mean=0.01)	CLASS_OK=0.0039 (67189/67452 (%99.61))	TimeGain_OptLoss=0.0039 (46180.95/125641.66,79.00/23215.00)@(67189:53412:13777,45(1.98%),218)	
	Test: LOSS F. (mean)=0.0188 (total=49.78,max=1.27,mean=0.02)	CLASS_OK=0.0044 (168407/169150 (%99.56))	TimeGain_OptLoss=0.0044 (117724.95/310762.57,280.00/58171.00)@(168407:134073:34334,148(2.39%),595)	
Epoch 007* 	 
	Train: LOSS F. (mean)=0.0075 (total=31.53,max=0.19,mean=0.01)	CLASS_OK=0.0042 (268668/269804 (%99.58))	TimeGain_OptLoss=0.0042 (184577.61/503264.08,58.00/92684.00)@(268668:213889:54779,48(0.53%),1088)	
	Val: LOSS F. (mean)=0.0113 (total=11.91,max=0.45,mean=0.01)	CLASS_OK=0.0044 (67158/67452 (%99.56))	TimeGain_OptLoss=0.0044 (45335.40/125641.66,36.00/23215.00)@(67158:53360:13798,24(1.14%),270)	
	Test: LOSS F. (mean)=0.0157 (total=41.56,max=1.06,mean=0.02)	CLASS_OK=0.0047 (168361/169150 (%99.53))	TimeGain_OptLoss=0.0047 (115495.02/310762.57,136.00/58171.00)@(168361:133970:34391,91(0.96%),698)	
Epoch 008* 	 
	Train: LOSS F. (mean)=0.0064 (total=26.94,max=0.26,mean=0.01)	CLASS_OK=0.0033 (268903/269804 (%99.67))	TimeGain_OptLoss=0.0033 (190065.14/503264.08,68.00/92684.00)@(268903:214126:54777,50(0.62%),851)	
	Val: LOSS F. (mean)=0.0123 (total=12.94,max=0.68,mean=0.01)	CLASS_OK=0.0037 (67203/67452 (%99.63))	TimeGain_OptLoss=0.0037 (46658.44/125641.66,54.00/23215.00)@(67203:53412:13791,31(1.28%),218)	
	Test: LOSS F. (mean)=0.0193 (total=51.08,max=1.36,mean=0.02)	CLASS_OK=0.0042 (168440/169150 (%99.58))	TimeGain_OptLoss=0.0042 (118553.10/310762.57,190.00/58171.00)@(168440:134074:34366,116(1.44%),594)	
Epoch 009 	 
	Train: LOSS F. (mean)=0.0094 (total=39.61,max=0.16,mean=0.01)	CLASS_OK=0.0045 (268597/269804 (%99.55))	TimeGain_OptLoss=0.0045 (180206.36/503264.08,37.00/92684.00)@(268597:213794:54803,24(0.20%),1183)	
	Val: LOSS F. (mean)=0.0124 (total=13.06,max=0.32,mean=0.01)	CLASS_OK=0.0049 (67121/67452 (%99.51))	TimeGain_OptLoss=0.0049 (43691.27/125641.66,44.00/23215.00)@(67121:53322:13799,23(0.88%),308)	
	Test: LOSS F. (mean)=0.0169 (total=44.68,max=0.51,mean=0.02)	CLASS_OK=0.0051 (168290/169150 (%99.49))	TimeGain_OptLoss=0.0051 (112969.95/310762.57,168.00/58171.00)@(168290:133908:34382,100(1.08%),760)	
Epoch 010 	 
	Train: LOSS F. (mean)=0.0065 (total=27.42,max=0.20,mean=0.01)	CLASS_OK=0.0038 (268787/269804 (%99.62))	TimeGain_OptLoss=0.0038 (185775.36/503264.08,88.00/92684.00)@(268787:214017:54770,57(0.54%),960)	
	Val: LOSS F. (mean)=0.0138 (total=14.59,max=0.94,mean=0.01)	CLASS_OK=0.0044 (67155/67452 (%99.56))	TimeGain_OptLoss=0.0044 (45128.41/125641.66,58.00/23215.00)@(67155:53366:13789,33(1.40%),264)	
	Test: LOSS F. (mean)=0.0221 (total=58.35,max=1.62,mean=0.02)	CLASS_OK=0.0044 (168400/169150 (%99.56))	TimeGain_OptLoss=0.0044 (116027.78/310762.57,180.00/58171.00)@(168400:134031:34369,113(1.51%),637)	
Epoch 011* 	 
	Train: LOSS F. (mean)=0.0060 (total=25.16,max=0.29,mean=0.01)	CLASS_OK=0.0036 (268839/269804 (%99.64))	TimeGain_OptLoss=0.0036 (187569.61/503264.08,61.00/92684.00)@(268839:214046:54793,34(0.48%),931)	
	Val: LOSS F. (mean)=0.0133 (total=13.98,max=0.75,mean=0.01)	CLASS_OK=0.0040 (67182/67452 (%99.60))	TimeGain_OptLoss=0.0040 (45758.06/125641.66,44.00/23215.00)@(67182:53383:13799,23(1.37%),247)	
	Test: LOSS F. (mean)=0.0202 (total=53.37,max=1.20,mean=0.02)	CLASS_OK=0.0041 (168452/169150 (%99.59))	TimeGain_OptLoss=0.0041 (117775.87/310762.57,186.00/58171.00)@(168452:134084:34368,114(1.44%),584)	
Epoch 012* 	 
	Train: LOSS F. (mean)=0.0057 (total=23.94,max=0.28,mean=0.01)	CLASS_OK=0.0033 (268927/269804 (%99.67))	TimeGain_OptLoss=0.0033 (188944.01/503264.08,66.00/92684.00)@(268927:214152:54775,52(0.47%),825)	
	Val: LOSS F. (mean)=0.0145 (total=15.31,max=0.97,mean=0.01)	CLASS_OK=0.0038 (67196/67452 (%99.62))	TimeGain_OptLoss=0.0038 (46166.16/125641.66,62.00/23215.00)@(67196:53413:13783,39(1.56%),217)	
	Test: LOSS F. (mean)=0.0224 (total=59.07,max=1.70,mean=0.02)	CLASS_OK=0.0040 (168466/169150 (%99.60))	TimeGain_OptLoss=0.0040 (117958.24/310762.57,181.00/58171.00)@(168466:134094:34372,110(1.27%),574)	
Epoch 013 	 
	Train: LOSS F. (mean)=0.0080 (total=33.60,max=0.38,mean=0.01)	CLASS_OK=0.0040 (268731/269804 (%99.60))	TimeGain_OptLoss=0.0040 (187045.53/503264.08,99.00/92684.00)@(268731:213985:54746,81(1.18%),992)	
	Val: LOSS F. (mean)=0.0120 (total=12.63,max=0.64,mean=0.01)	CLASS_OK=0.0042 (67169/67452 (%99.58))	TimeGain_OptLoss=0.0042 (45628.87/125641.66,44.00/23215.00)@(67169:53380:13789,33(1.54%),250)	
	Test: LOSS F. (mean)=0.0179 (total=47.38,max=0.88,mean=0.02)	CLASS_OK=0.0048 (168333/169150 (%99.52))	TimeGain_OptLoss=0.0048 (115775.71/310762.57,194.00/58171.00)@(168333:133972:34361,121(1.89%),696)	
Epoch 014 	 
	Train: LOSS F. (mean)=0.0119 (total=50.03,max=0.43,mean=0.01)	CLASS_OK=0.0070 (267920/269804 (%99.30))	TimeGain_OptLoss=0.0070 (156979.11/503264.08,7.00/92684.00)@(267920:213098:54822,5(0.05%),1879)	
	Val: LOSS F. (mean)=0.0177 (total=18.61,max=1.84,mean=0.02)	CLASS_OK=0.0075 (66945/67452 (%99.25))	TimeGain_OptLoss=0.0075 (37357.59/125641.66,17.00/23215.00)@(66945:53133:13812,10(0.33%),497)	
	Test: LOSS F. (mean)=0.0277 (total=73.34,max=1.71,mean=0.03)	CLASS_OK=0.0072 (167940/169150 (%99.28))	TimeGain_OptLoss=0.0072 (99450.39/310762.57,115.00/58171.00)@(167940:133525:34415,67(0.63%),1143)	
Epoch 015 	 
	Train: LOSS F. (mean)=0.0151 (total=63.75,max=0.23,mean=0.02)	CLASS_OK=0.0060 (268180/269804 (%99.40))	TimeGain_OptLoss=0.0060 (195065.19/503264.08,75.00/92684.00)@(268180:213417:54763,64(1.03%),1560)	
	Val: LOSS F. (mean)=0.0208 (total=21.95,max=0.61,mean=0.02)	CLASS_OK=0.0067 (67000/67452 (%99.33))	TimeGain_OptLoss=0.0067 (48074.09/125641.66,49.00/23215.00)@(67000:53218:13782,40(2.33%),412)	
	Test: LOSS F. (mean)=0.0249 (total=65.94,max=1.03,mean=0.02)	CLASS_OK=0.0068 (168004/169150 (%99.32))	TimeGain_OptLoss=0.0068 (121449.42/310762.57,216.00/58171.00)@(168004:133641:34363,119(1.98%),1027)	
Epoch 016 	 
	Train: LOSS F. (mean)=0.0065 (total=27.37,max=0.64,mean=0.01)	CLASS_OK=0.0032 (268930/269804 (%99.68))	TimeGain_OptLoss=0.0032 (191234.56/503264.08,95.00/92684.00)@(268930:214176:54754,73(0.64%),801)	
	Val: LOSS F. (mean)=0.0236 (total=24.91,max=1.64,mean=0.02)	CLASS_OK=0.0040 (67179/67452 (%99.60))	TimeGain_OptLoss=0.0040 (47177.62/125641.66,80.00/23215.00)@(67179:53413:13766,56(2.13%),217)	
	Test: LOSS F. (mean)=0.0291 (total=76.80,max=1.87,mean=0.03)	CLASS_OK=0.0042 (168442/169150 (%99.58))	TimeGain_OptLoss=0.0042 (118772.22/310762.57,265.00/58171.00)@(168442:134106:34336,146(1.70%),562)	
Epoch 017* 	 
	Train: LOSS F. (mean)=0.0052 (total=22.00,max=0.24,mean=0.01)	CLASS_OK=0.0036 (268838/269804 (%99.64))	TimeGain_OptLoss=0.0036 (184938.20/503264.08,29.00/92684.00)@(268838:214034:54804,23(0.14%),943)	
	Val: LOSS F. (mean)=0.0133 (total=14.01,max=1.06,mean=0.01)	CLASS_OK=0.0043 (67163/67452 (%99.57))	TimeGain_OptLoss=0.0043 (45069.74/125641.66,57.00/23215.00)@(67163:53375:13788,34(1.37%),255)	
	Test: LOSS F. (mean)=0.0179 (total=47.28,max=1.35,mean=0.02)	CLASS_OK=0.0045 (168393/169150 (%99.55))	TimeGain_OptLoss=0.0045 (114479.11/310762.57,160.00/58171.00)@(168393:134004:34389,93(1.08%),664)	
Epoch 018 	 
	Train: LOSS F. (mean)=0.0057 (total=24.00,max=0.52,mean=0.01)	CLASS_OK=0.0030 (268995/269804 (%99.70))	TimeGain_OptLoss=0.0030 (196506.30/503264.08,73.00/92684.00)@(268995:214231:54764,63(1.05%),746)	
	Val: LOSS F. (mean)=0.0178 (total=18.79,max=3.40,mean=0.02)	CLASS_OK=0.0038 (67194/67452 (%99.62))	TimeGain_OptLoss=0.0038 (47842.71/125641.66,61.00/23215.00)@(67194:53414:13780,42(2.27%),216)	
	Test: LOSS F. (mean)=0.0275 (total=72.62,max=2.97,mean=0.03)	CLASS_OK=0.0042 (168439/169150 (%99.58))	TimeGain_OptLoss=0.0042 (121648.68/310762.57,271.00/58171.00)@(168439:134108:34331,151(2.28%),560)	
Epoch 019 	 
	Train: LOSS F. (mean)=0.0060 (total=25.23,max=0.47,mean=0.01)	CLASS_OK=0.0024 (269146/269804 (%99.76))	TimeGain_OptLoss=0.0024 (202242.68/503264.08,138.00/92684.00)@(269146:214416:54730,97(1.61%),561)	
	Val: LOSS F. (mean)=0.0195 (total=20.59,max=3.16,mean=0.02)	CLASS_OK=0.0034 (67225/67452 (%99.66))	TimeGain_OptLoss=0.0034 (49496.10/125641.66,89.00/23215.00)@(67225:53460:13765,57(3.05%),170)	
	Test: LOSS F. (mean)=0.0271 (total=71.57,max=3.07,mean=0.03)	CLASS_OK=0.0038 (168515/169150 (%99.62))	TimeGain_OptLoss=0.0038 (126401.59/310762.57,299.00/58171.00)@(168515:134214:34301,181(3.36%),454)	
Epoch 020* 	 
	Train: LOSS F. (mean)=0.0048 (total=20.16,max=0.39,mean=0.00)	CLASS_OK=0.0031 (268977/269804 (%99.69))	TimeGain_OptLoss=0.0031 (188865.41/503264.08,49.00/92684.00)@(268977:214177:54800,27(0.06%),800)	
	Val: LOSS F. (mean)=0.0179 (total=18.81,max=2.51,mean=0.02)	CLASS_OK=0.0037 (67201/67452 (%99.63))	TimeGain_OptLoss=0.0037 (46006.75/125641.66,54.00/23215.00)@(67201:53407:13794,28(1.05%),223)	
	Test: LOSS F. (mean)=0.0275 (total=72.57,max=3.02,mean=0.03)	CLASS_OK=0.0041 (168449/169150 (%99.59))	TimeGain_OptLoss=0.0041 (117136.19/310762.57,211.00/58171.00)@(168449:134092:34357,125(1.37%),576)	
Epoch 021* 	 
	Train: LOSS F. (mean)=0.0047 (total=19.72,max=0.24,mean=0.00)	CLASS_OK=0.0027 (269087/269804 (%99.73))	TimeGain_OptLoss=0.0027 (197033.19/503264.08,74.00/92684.00)@(269087:214319:54768,59(0.96%),658)	
	Val: LOSS F. (mean)=0.0180 (total=18.98,max=2.39,mean=0.02)	CLASS_OK=0.0034 (67225/67452 (%99.66))	TimeGain_OptLoss=0.0034 (48028.53/125641.66,60.00/23215.00)@(67225:53444:13781,41(2.03%),186)	
	Test: LOSS F. (mean)=0.0259 (total=68.43,max=2.39,mean=0.03)	CLASS_OK=0.0038 (168500/169150 (%99.62))	TimeGain_OptLoss=0.0038 (122097.77/310762.57,248.00/58171.00)@(168500:134155:34345,137(2.04%),513)	
Epoch 022 	 
	Train: LOSS F. (mean)=0.0060 (total=25.45,max=0.23,mean=0.01)	CLASS_OK=0.0030 (269007/269804 (%99.70))	TimeGain_OptLoss=0.0030 (194992.65/503264.08,68.00/92684.00)@(269007:214240:54767,60(1.00%),737)	
	Val: LOSS F. (mean)=0.0173 (total=18.20,max=1.85,mean=0.02)	CLASS_OK=0.0036 (67208/67452 (%99.64))	TimeGain_OptLoss=0.0036 (47180.16/125641.66,50.00/23215.00)@(67208:53425:13783,39(1.88%),205)	
	Test: LOSS F. (mean)=0.0266 (total=70.34,max=2.19,mean=0.03)	CLASS_OK=0.0040 (168470/169150 (%99.60))	TimeGain_OptLoss=0.0040 (120664.75/310762.57,194.00/58171.00)@(168470:134105:34365,117(1.70%),563)	
