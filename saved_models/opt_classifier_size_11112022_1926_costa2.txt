Command line: main.py -ds 1 -ts 0 -e 22 -m nn_models.Model_3 -lt clasification -lf cross_entropy -of tmp/last_model_cl.pyt

Loading dataset with id 1
Loading dataset with id 0
Creating model: nn_models.Model_3
Cross entropy weights: tensor([0.2051, 0.7949])

Model: Model_3(
  (emb): Embedding(141, 64, padding_idx=0)
  (rnn): LSTM(64, 128)
  (lin): Linear(in_features=128, out_features=2, bias=True)
  (lin1): Linear(in_features=128, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=128, bias=True)
)

Loss function: CrossEntropyLoss()

Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)


** The training set (80.00% for training and 20.00% for validation)

Dataset: SequenceBasedBasicBlocksDataset(172476):
====================
Number of sequences: 172476
Input sizes: 141
Class distribution:
===================
Number of classes: 2

{0: '137099 (79.49)% ', 1: '35377 (20.51)% '}


** The test set

Dataset: SequenceBasedBasicBlocksDataset(63583):
====================
Number of sequences: 63583
Input sizes: 141
Class distribution:
===================
Number of classes: 2

{0: '50905 (80.06)% ', 1: '12678 (19.94)% '}


Epoch 001* 	 
	Train: LOSS F. (mean)=0.0234 (total=50.55,max=0.44,mean=0.02)	CLASS_OK=0.0093 (136692/137980 (%99.07))	TimeGain_OptLoss=0.0093 (76805.27/256720.02,197.00/47303.00)@(136692:108564:28128,127(2.08%),1161)	
	Val: LOSS F. (mean)=0.0256 (total=13.78,max=0.45,mean=0.03)	CLASS_OK=0.0091 (34181/34496 (%99.09))	TimeGain_OptLoss=0.0091 (19094.61/62623.22,69.00/11691.00)@(34181:27103:7078,44(1.70%),271)	
	Test: LOSS F. (mean)=0.0411 (total=40.87,max=0.50,mean=0.04)	CLASS_OK=0.0116 (62845/63583 (%98.84))	TimeGain_OptLoss=0.0116 (31798.27/115057.08,181.00/21672.00)@(62845:50310:12535,143(2.17%),595)	
Epoch 002* 	 
	Train: LOSS F. (mean)=0.0168 (total=36.19,max=0.34,mean=0.02)	CLASS_OK=0.0047 (137328/137980 (%99.53))	TimeGain_OptLoss=0.0047 (108661.26/256720.02,289.00/47303.00)@(137328:109266:28062,193(5.37%),459)	
	Val: LOSS F. (mean)=0.0219 (total=11.78,max=0.37,mean=0.02)	CLASS_OK=0.0054 (34308/34496 (%99.46))	TimeGain_OptLoss=0.0054 (26381.68/62623.22,110.00/11691.00)@(34308:27255:7053,69(5.87%),119)	
	Test: LOSS F. (mean)=0.0328 (total=32.58,max=0.47,mean=0.03)	CLASS_OK=0.0067 (63154/63583 (%99.33))	TimeGain_OptLoss=0.0067 (44881.07/115057.08,256.00/21672.00)@(63154:50647:12507,171(5.63%),258)	
Epoch 003* 	 
	Train: LOSS F. (mean)=0.0144 (total=31.11,max=0.26,mean=0.01)	CLASS_OK=0.0041 (137411/137980 (%99.59))	TimeGain_OptLoss=0.0041 (108443.47/256720.02,218.00/47303.00)@(137411:109318:28093,162(4.53%),407)	
	Val: LOSS F. (mean)=0.0176 (total=9.48,max=0.23,mean=0.02)	CLASS_OK=0.0043 (34346/34496 (%99.57))	TimeGain_OptLoss=0.0043 (26212.56/62623.22,80.00/11691.00)@(34346:27275:7071,51(4.62%),99)	
	Test: LOSS F. (mean)=0.0295 (total=29.28,max=0.38,mean=0.03)	CLASS_OK=0.0076 (63101/63583 (%99.24))	TimeGain_OptLoss=0.0076 (44641.24/115057.08,293.00/21672.00)@(63101:50623:12478,200(4.93%),282)	
Epoch 004* 	 
	Train: LOSS F. (mean)=0.0104 (total=22.45,max=0.11,mean=0.01)	CLASS_OK=0.0052 (137265/137980 (%99.48))	TimeGain_OptLoss=0.0052 (90382.38/256720.02,44.00/47303.00)@(137265:109040:28225,30(0.21%),685)	
	Val: LOSS F. (mean)=0.0138 (total=7.44,max=0.34,mean=0.01)	CLASS_OK=0.0059 (34291/34496 (%99.41))	TimeGain_OptLoss=0.0059 (21499.49/62623.22,32.00/11691.00)@(34291:27189:7102,20(0.87%),185)	
	Test: LOSS F. (mean)=0.0245 (total=24.38,max=0.76,mean=0.02)	CLASS_OK=0.0075 (63106/63583 (%99.25))	TimeGain_OptLoss=0.0075 (37627.00/115057.08,136.00/21672.00)@(63106:50512:12594,84(1.49%),393)	
Epoch 005* 	 
	Train: LOSS F. (mean)=0.0086 (total=18.56,max=0.17,mean=0.01)	CLASS_OK=0.0037 (137466/137980 (%99.63))	TimeGain_OptLoss=0.0037 (105314.28/256720.02,90.00/47303.00)@(137466:109293:28173,82(3.32%),432)	
	Val: LOSS F. (mean)=0.0133 (total=7.15,max=0.57,mean=0.01)	CLASS_OK=0.0042 (34350/34496 (%99.58))	TimeGain_OptLoss=0.0042 (25259.21/62623.22,40.00/11691.00)@(34350:27255:7095,27(3.78%),119)	
	Test: LOSS F. (mean)=0.0323 (total=32.13,max=0.87,mean=0.03)	CLASS_OK=0.0066 (63164/63583 (%99.34))	TimeGain_OptLoss=0.0066 (42622.82/115057.08,136.00/21672.00)@(63164:50585:12579,99(3.03%),320)	
Epoch 006* 	 
	Train: LOSS F. (mean)=0.0077 (total=16.52,max=0.13,mean=0.01)	CLASS_OK=0.0042 (137402/137980 (%99.58))	TimeGain_OptLoss=0.0042 (92451.28/256720.02,25.00/47303.00)@(137402:109161:28241,14(0.17%),564)	
	Val: LOSS F. (mean)=0.0145 (total=7.81,max=0.99,mean=0.01)	CLASS_OK=0.0051 (34321/34496 (%99.49))	TimeGain_OptLoss=0.0051 (22015.16/62623.22,24.00/11691.00)@(34321:27214:7107,15(0.89%),160)	
	Test: LOSS F. (mean)=0.0279 (total=27.76,max=0.69,mean=0.03)	CLASS_OK=0.0063 (63180/63583 (%99.37))	TimeGain_OptLoss=0.0063 (38817.25/115057.08,142.00/21672.00)@(63180:50605:12575,103(1.44%),300)	
Epoch 007* 	 
	Train: LOSS F. (mean)=0.0076 (total=16.49,max=0.18,mean=0.01)	CLASS_OK=0.0047 (137336/137980 (%99.53))	TimeGain_OptLoss=0.0047 (91814.02/256720.02,12.00/47303.00)@(137336:109090:28246,9(0.08%),635)	
	Val: LOSS F. (mean)=0.0117 (total=6.33,max=0.49,mean=0.01)	CLASS_OK=0.0052 (34315/34496 (%99.48))	TimeGain_OptLoss=0.0052 (22021.74/62623.22,20.00/11691.00)@(34315:27207:7108,14(0.89%),167)	
	Test: LOSS F. (mean)=0.0314 (total=31.17,max=1.08,mean=0.03)	CLASS_OK=0.0065 (63171/63583 (%99.35))	TimeGain_OptLoss=0.0065 (38580.19/115057.08,131.00/21672.00)@(63171:50574:12597,81(1.92%),331)	
Epoch 008* 	 
	Train: LOSS F. (mean)=0.0060 (total=12.90,max=0.13,mean=0.01)	CLASS_OK=0.0038 (137455/137980 (%99.62))	TimeGain_OptLoss=0.0038 (95403.29/256720.02,24.00/47303.00)@(137455:109217:28238,17(0.26%),508)	
	Val: LOSS F. (mean)=0.0135 (total=7.28,max=0.52,mean=0.01)	CLASS_OK=0.0051 (34320/34496 (%99.49))	TimeGain_OptLoss=0.0051 (22595.47/62623.22,32.00/11691.00)@(34320:27219:7101,21(1.43%),155)	
	Test: LOSS F. (mean)=0.0258 (total=25.68,max=0.92,mean=0.03)	CLASS_OK=0.0057 (63220/63583 (%99.43))	TimeGain_OptLoss=0.0057 (39988.69/115057.08,161.00/21672.00)@(63220:50645:12575,103(2.59%),260)	
Epoch 009 	 
	Train: LOSS F. (mean)=0.0063 (total=13.53,max=0.14,mean=0.01)	CLASS_OK=0.0040 (137422/137980 (%99.60))	TimeGain_OptLoss=0.0040 (93089.78/256720.02,29.00/47303.00)@(137422:109184:28238,17(0.22%),541)	
	Val: LOSS F. (mean)=0.0133 (total=7.18,max=0.74,mean=0.01)	CLASS_OK=0.0051 (34320/34496 (%99.49))	TimeGain_OptLoss=0.0051 (22024.99/62623.22,27.00/11691.00)@(34320:27215:7105,17(1.35%),159)	
	Test: LOSS F. (mean)=0.0272 (total=27.06,max=0.91,mean=0.03)	CLASS_OK=0.0062 (63187/63583 (%99.38))	TimeGain_OptLoss=0.0062 (38912.89/115057.08,152.00/21672.00)@(63187:50611:12576,102(2.28%),294)	
Epoch 010 	 
	Train: LOSS F. (mean)=0.0070 (total=15.13,max=0.14,mean=0.01)	CLASS_OK=0.0032 (137533/137980 (%99.68))	TimeGain_OptLoss=0.0032 (96784.90/256720.02,72.00/47303.00)@(137533:109317:28216,39(0.66%),408)	
	Val: LOSS F. (mean)=0.0150 (total=8.08,max=0.68,mean=0.01)	CLASS_OK=0.0044 (34344/34496 (%99.56))	TimeGain_OptLoss=0.0044 (23257.72/62623.22,49.00/11691.00)@(34344:27253:7091,31(1.75%),121)	
	Test: LOSS F. (mean)=0.0375 (total=37.32,max=1.00,mean=0.04)	CLASS_OK=0.0064 (63174/63583 (%99.36))	TimeGain_OptLoss=0.0064 (42323.31/115057.08,242.00/21672.00)@(63174:50649:12525,153(5.36%),256)	
Epoch 011* 	 
	Train: LOSS F. (mean)=0.0050 (total=10.75,max=0.08,mean=0.00)	CLASS_OK=0.0033 (137526/137980 (%99.67))	TimeGain_OptLoss=0.0033 (96067.66/256720.02,12.00/47303.00)@(137526:109282:28244,11(0.26%),443)	
	Val: LOSS F. (mean)=0.0133 (total=7.17,max=0.53,mean=0.01)	CLASS_OK=0.0045 (34342/34496 (%99.55))	TimeGain_OptLoss=0.0045 (23248.26/62623.22,35.00/11691.00)@(34342:27243:7099,23(1.60%),131)	
	Test: LOSS F. (mean)=0.0331 (total=32.89,max=1.15,mean=0.03)	CLASS_OK=0.0056 (63227/63583 (%99.44))	TimeGain_OptLoss=0.0056 (40754.39/115057.08,150.00/21672.00)@(63227:50642:12585,93(2.19%),263)	
Epoch 012 	 
	Train: LOSS F. (mean)=0.0059 (total=12.63,max=0.11,mean=0.01)	CLASS_OK=0.0035 (137502/137980 (%99.65))	TimeGain_OptLoss=0.0035 (95613.72/256720.02,24.00/47303.00)@(137502:109262:28240,15(0.36%),463)	
	Val: LOSS F. (mean)=0.0124 (total=6.68,max=0.55,mean=0.01)	CLASS_OK=0.0045 (34342/34496 (%99.55))	TimeGain_OptLoss=0.0045 (23223.12/62623.22,31.00/11691.00)@(34342:27239:7103,19(1.49%),135)	
	Test: LOSS F. (mean)=0.0258 (total=25.62,max=1.01,mean=0.03)	CLASS_OK=0.0055 (63236/63583 (%99.45))	TimeGain_OptLoss=0.0055 (40147.74/115057.08,110.00/21672.00)@(63236:50623:12613,65(1.41%),282)	
Epoch 013* 	 
	Train: LOSS F. (mean)=0.0047 (total=10.17,max=0.13,mean=0.00)	CLASS_OK=0.0023 (137665/137980 (%99.77))	TimeGain_OptLoss=0.0023 (104963.95/256720.02,42.00/47303.00)@(137665:109449:28216,39(1.53%),276)	
	Val: LOSS F. (mean)=0.0139 (total=7.50,max=0.67,mean=0.01)	CLASS_OK=0.0032 (34385/34496 (%99.68))	TimeGain_OptLoss=0.0032 (25379.86/62623.22,32.00/11691.00)@(34385:27285:7100,22(2.04%),89)	
	Test: LOSS F. (mean)=0.0353 (total=35.09,max=1.59,mean=0.04)	CLASS_OK=0.0045 (63295/63583 (%99.55))	TimeGain_OptLoss=0.0045 (44063.37/115057.08,141.00/21672.00)@(63295:50710:12585,93(2.95%),195)	
Epoch 014 	 
	Train: LOSS F. (mean)=0.0057 (total=12.34,max=0.21,mean=0.01)	CLASS_OK=0.0025 (137640/137980 (%99.75))	TimeGain_OptLoss=0.0025 (105467.11/256720.02,43.00/47303.00)@(137640:109423:28217,38(1.43%),302)	
	Val: LOSS F. (mean)=0.0189 (total=10.21,max=1.03,mean=0.02)	CLASS_OK=0.0037 (34370/34496 (%99.63))	TimeGain_OptLoss=0.0037 (25386.22/62623.22,29.00/11691.00)@(34370:27270:7100,22(2.16%),104)	
	Test: LOSS F. (mean)=0.0477 (total=47.41,max=2.09,mean=0.05)	CLASS_OK=0.0052 (63250/63583 (%99.48))	TimeGain_OptLoss=0.0052 (44373.13/115057.08,141.00/21672.00)@(63250:50664:12586,92(3.69%),241)	
Epoch 015 	 
	Train: LOSS F. (mean)=0.0053 (total=11.43,max=0.12,mean=0.01)	CLASS_OK=0.0025 (137633/137980 (%99.75))	TimeGain_OptLoss=0.0025 (104738.08/256720.02,53.00/47303.00)@(137633:109421:28212,43(1.53%),304)	
	Val: LOSS F. (mean)=0.0173 (total=9.31,max=1.21,mean=0.02)	CLASS_OK=0.0033 (34382/34496 (%99.67))	TimeGain_OptLoss=0.0033 (25118.73/62623.22,26.00/11691.00)@(34382:27279:7103,19(1.87%),95)	
	Test: LOSS F. (mean)=0.0378 (total=37.55,max=1.71,mean=0.04)	CLASS_OK=0.0052 (63251/63583 (%99.48))	TimeGain_OptLoss=0.0052 (42882.25/115057.08,164.00/21672.00)@(63251:50677:12574,104(2.49%),228)	
Epoch 016* 	 
	Train: LOSS F. (mean)=0.0046 (total=9.92,max=0.11,mean=0.00)	CLASS_OK=0.0022 (137678/137980 (%99.78))	TimeGain_OptLoss=0.0022 (103573.48/256720.02,38.00/47303.00)@(137678:109455:28223,32(1.07%),270)	
	Val: LOSS F. (mean)=0.0178 (total=9.60,max=1.14,mean=0.02)	CLASS_OK=0.0029 (34395/34496 (%99.71))	TimeGain_OptLoss=0.0029 (25161.52/62623.22,31.00/11691.00)@(34395:27294:7101,21(1.90%),80)	
	Test: LOSS F. (mean)=0.0435 (total=43.26,max=1.32,mean=0.04)	CLASS_OK=0.0047 (63282/63583 (%99.53))	TimeGain_OptLoss=0.0047 (43383.39/115057.08,160.00/21672.00)@(63282:50702:12580,98(2.20%),203)	
Epoch 017 	 
	Train: LOSS F. (mean)=0.0053 (total=11.51,max=0.71,mean=0.01)	CLASS_OK=0.0020 (137698/137980 (%99.80))	TimeGain_OptLoss=0.0020 (105051.55/256720.02,60.00/47303.00)@(137698:109494:28204,51(1.45%),231)	
	Val: LOSS F. (mean)=0.0196 (total=10.55,max=1.36,mean=0.02)	CLASS_OK=0.0027 (34403/34496 (%99.73))	TimeGain_OptLoss=0.0027 (25638.39/62623.22,38.00/11691.00)@(34403:27309:7094,28(1.99%),65)	
	Test: LOSS F. (mean)=0.0575 (total=57.13,max=1.49,mean=0.06)	CLASS_OK=0.0051 (63258/63583 (%99.49))	TimeGain_OptLoss=0.0051 (44399.42/115057.08,218.00/21672.00)@(63258:50731:12527,151(3.82%),174)	
Epoch 018* 	 
	Train: LOSS F. (mean)=0.0042 (total=9.04,max=0.12,mean=0.00)	CLASS_OK=0.0020 (137701/137980 (%99.80))	TimeGain_OptLoss=0.0020 (103954.04/256720.02,39.00/47303.00)@(137701:109480:28221,34(1.15%),245)	
	Val: LOSS F. (mean)=0.0191 (total=10.29,max=1.63,mean=0.02)	CLASS_OK=0.0030 (34392/34496 (%99.70))	TimeGain_OptLoss=0.0030 (25317.38/62623.22,35.00/11691.00)@(34392:27295:7097,25(2.30%),79)	
	Test: LOSS F. (mean)=0.0472 (total=46.90,max=1.29,mean=0.05)	CLASS_OK=0.0048 (63279/63583 (%99.52))	TimeGain_OptLoss=0.0048 (43227.64/115057.08,145.00/21672.00)@(63279:50699:12580,98(2.42%),206)	
Epoch 019 	 
	Train: LOSS F. (mean)=0.0062 (total=13.27,max=0.82,mean=0.01)	CLASS_OK=0.0040 (137431/137980 (%99.60))	TimeGain_OptLoss=0.0040 (93814.30/256720.02,5.00/47303.00)@(137431:109180:28251,4(0.12%),545)	
	Val: LOSS F. (mean)=0.0132 (total=7.10,max=0.80,mean=0.01)	CLASS_OK=0.0047 (34334/34496 (%99.53))	TimeGain_OptLoss=0.0047 (22480.19/62623.22,16.00/11691.00)@(34334:27224:7110,12(0.98%),150)	
	Test: LOSS F. (mean)=0.0465 (total=46.25,max=1.44,mean=0.05)	CLASS_OK=0.0064 (63176/63583 (%99.36))	TimeGain_OptLoss=0.0064 (39338.27/115057.08,109.00/21672.00)@(63176:50571:12605,73(1.57%),334)	
Epoch 020 	 
	Train: LOSS F. (mean)=0.0046 (total=9.95,max=0.09,mean=0.00)	CLASS_OK=0.0026 (137619/137980 (%99.74))	TimeGain_OptLoss=0.0026 (104101.62/256720.02,25.00/47303.00)@(137619:109389:28230,25(1.10%),336)	
	Val: LOSS F. (mean)=0.0147 (total=7.93,max=1.04,mean=0.01)	CLASS_OK=0.0037 (34369/34496 (%99.63))	TimeGain_OptLoss=0.0037 (25421.84/62623.22,30.00/11691.00)@(34369:27269:7100,22(2.05%),105)	
	Test: LOSS F. (mean)=0.0305 (total=30.34,max=0.95,mean=0.03)	CLASS_OK=0.0054 (63242/63583 (%99.46))	TimeGain_OptLoss=0.0054 (43007.11/115057.08,134.00/21672.00)@(63242:50655:12587,91(2.11%),250)	
Epoch 021 	 
	Train: LOSS F. (mean)=0.0054 (total=11.57,max=0.14,mean=0.01)	CLASS_OK=0.0031 (137551/137980 (%99.69))	TimeGain_OptLoss=0.0031 (96846.57/256720.02,24.00/47303.00)@(137551:109310:28241,14(0.16%),415)	
	Val: LOSS F. (mean)=0.0201 (total=10.85,max=1.22,mean=0.02)	CLASS_OK=0.0046 (34338/34496 (%99.54))	TimeGain_OptLoss=0.0046 (22962.26/62623.22,31.00/11691.00)@(34338:27237:7101,21(1.34%),137)	
	Test: LOSS F. (mean)=0.0409 (total=40.61,max=1.20,mean=0.04)	CLASS_OK=0.0059 (63207/63583 (%99.41))	TimeGain_OptLoss=0.0059 (40813.90/115057.08,156.00/21672.00)@(63207:50626:12581,97(2.18%),279)	
Epoch 022* 	 
	Train: LOSS F. (mean)=0.0038 (total=8.18,max=0.40,mean=0.00)	CLASS_OK=0.0018 (137728/137980 (%99.82))	TimeGain_OptLoss=0.0018 (104834.49/256720.02,40.00/47303.00)@(137728:109506:28222,33(1.10%),219)	
	Val: LOSS F. (mean)=0.0199 (total=10.70,max=1.19,mean=0.02)	CLASS_OK=0.0031 (34390/34496 (%99.69))	TimeGain_OptLoss=0.0031 (25330.02/62623.22,38.00/11691.00)@(34390:27294:7096,26(2.37%),80)	
	Test: LOSS F. (mean)=0.0553 (total=54.93,max=1.75,mean=0.06)	CLASS_OK=0.0045 (63299/63583 (%99.55))	TimeGain_OptLoss=0.0045 (43627.78/115057.08,136.00/21672.00)@(63299:50716:12583,95(2.45%),189)	
